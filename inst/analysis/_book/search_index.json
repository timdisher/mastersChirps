[["index.html", "Masters analysis Report 1 Project Information 1.1 Ideas explored", " Masters analysis Report Tim Disher 2021-04-18 1 Project Information This project uses a Masters pool that me and some friends joined as a way to explore web/pdf scraping and a quick/fun look at clustering with PCA and growth mixture models. This was intended as a quick project for the sake of learning so analyses are not as rigorous as would be expected for a serious project. Prepare for typos! 1.1 Ideas explored In addition to practicing analyses this project also provides a sandbox for some of the project workflow/visualization ideas I am working on: Use of bookdown to organize analyses using serve_book() instead of sourcing scripts. .gitignore that requires explicit inclusion of data files Use of {xaringan}/{xaringanthemer} Use of {data.validator} for data validation Use of gghighlight "],["import-and-clean-data.html", "2 Import and Clean Data 2.1 Selection Data 2.2 Leaderboard Data 2.3 Calculate Daily Scores for Pool Participants", " 2 Import and Clean Data 2.1 Selection Data The original dataset was organized based on how the the pool was run with picks in columns. We will want to make this much wider by having each golfer as a column with a binary indicator of whether or not a given member of the pool selected them. We create some variable tests at the same time. data(&quot;entry_picks_anon&quot;) wide_dat &lt;- entry_picks_anon %&gt;% pivot_longer(cols = -alt_name) %&gt;% mutate(name = value, value = 1) %&gt;% pivot_wider(names_from = name, values_from= value) %&gt;% mutate_at(vars(-alt_name), ~ ifelse(is.na(.), 0, .)) report &lt;- data_validation_report() golfers &lt;- entry_picks_anon %&gt;% select(-alt_name) %&gt;% unlist() %&gt;% unique test_picks &lt;- all(wide_dat %&gt;% mutate(tot_pick = rowSums(across( `Jon Rahm`:`Robert MacIntyre` ))) %&gt;% pull(tot_pick) == 8) validate(wide_dat, &quot;Validate player selection data&quot;) %&gt;% validate_if(description = &quot;Verify everyone has 8 picks and nobody has any NA&quot;, all(test_picks), ) %&gt;% validate_cols(description = &quot;Test all values are 0 or 1&quot;, in_set(0, 1), -alt_name) %&gt;% validate_if(description = &quot;Test all 272 players are present&quot;, nrow(wide_dat) == 272) %&gt;% validate_if(description = &quot;Test all golders are present&quot;, all(golfers %in% colnames(wide_dat))) %&gt;% add_results(report) 2.2 Leaderboard Data The leaderboard data has to be organized in order to allow for calculating the daily ranks of each player. This data is pulled directly from the ESPN leaderboard using the rvest package. Code for html scraping can be found in /data-raw/leaderboard.R. data(&quot;leaderboard&quot;) datatable(leaderboard, rownames = FALSE, colnames = c(&quot;Player&quot;, &quot;Position&quot;, &quot;Total Score&quot;, paste(&quot;Day&quot;, 1:4))) The rules for the pool were not entirely clear with respect to handling players that didn’t make the second day cut, but it seemed to follow that they just kept their original ranking from the end of day 2. This is a little different from the official leaderboard, where DQs are dropped to the bottom. We use rowCumsums to get the cumulative score for each player and then call a quick custom ranking function to make sure ties are coded correctly. All golfers are included in the first day and then those in the group that made the day 2 cut are then separated out after that. Players who don’t make the cut still have their day 2 ranks carried forward. # Order of variables for later order &lt;- quo(c(player:tot, r1:r4, r1_rank, r2_rank, r3_rank, r4_rank)) # Day 1:2 pre_cut &lt;- leaderboard %&gt;% dplyr::select(r1:r2) %&gt;% as.matrix() %&gt;% matrixStats::rowCumsums() %&gt;% # Get cumulative score `colnames&lt;-`(paste0(&quot;r&quot;,1:2)) %&gt;% cbind(leaderboard %&gt;% dplyr::select(-c(r1:r2))) %&gt;% tibble::as_tibble() %&gt;% ties(., var = r1) %&gt;% # Score ties for day 1 ties(., var = r2) # Score ties for day 2 # Day 3 on limited to those who made the cut. Start from full leaderboard # to make sur eyou get the right cumulative scores made_cut &lt;- leaderboard %&gt;% dplyr::filter(!is.na(pos)) ranks_made &lt;- made_cut %&gt;% dplyr::select(r1,r2,r3,r4) %&gt;% as.matrix() %&gt;% matrixStats::rowCumsums() %&gt;% # na.rm by default `colnames&lt;-`(paste0(&quot;r&quot;,1:4)) %&gt;% cbind(made_cut %&gt;% dplyr::select(-c(r1,r2,r3,r4))) %&gt;% tibble::as_tibble() %&gt;% ties(., var = r3) %&gt;% ties(., var = r4) %&gt;% left_join(pre_cut %&gt;% select(player, ends_with(&quot;rank&quot;))) %&gt;% select(!! order) ranks_cut &lt;- pre_cut %&gt;% dplyr::filter(is.na(pos)) %&gt;% dplyr::mutate(r3_rank = r2_rank, r4_rank = r2_rank) %&gt;% select(!! order) score_dat &lt;- rbind(ranks_made, ranks_cut) # Add data tests validate(score_dat, &quot;Validate leaderboard data&quot;) %&gt;% validate_if(all(ranks_made$pos == ranks_made$r4_rank), description = &quot;Verify ranks calculated by hand against the current position. If TRUE, assumes the other days are correct as well.&quot;) %&gt;% validate_if(description = &quot;Test that highest score matches current score. Assume all the other days are correct if passes&quot;,all(ranks_made$r4 == ranks_made$tot)) %&gt;% add_results(report) 2.3 Calculate Daily Scores for Pool Participants The final step of data prep is to combine the golfer daily scores with the player choices in order to calculate the score of each day of the tournament. This is calculated as the sum of the ranks of the players that each person chose. For example if your 8 players are in positions 1, 2, 3, 4, 5, 6, 7, 8 then your score would be 36. A first step here however is to correct some differences in the names between the pool and the ESPN leaderboard. These are just some small spelling differences that are easier to change in leaderboard data than the other. golfers[!golfers %in% score_dat$player] ## [1] &quot;Bryson Dechambeau&quot; &quot;Ollie Osborne&quot; &quot;Tyler Strafaci&quot; score_dat &lt;- score_dat %&gt;% mutate(player = case_when(player == &quot;Bryson DeChambeau&quot; ~ &quot;Bryson Dechambeau&quot;, player == &quot;Charles Osborne (a)&quot; ~ &quot;Ollie Osborne&quot;, player == &quot;Tyler Strafaci (a)&quot; ~ &quot;Tyler Strafaci&quot;, TRUE ~ player)) The final step in data prep is to calculate the daily scores for everyone in the pool. This is done by looping over rows in the pick data frame and and then for each user calculate the sum of their player ranks for each day by matching them to the score data. We test these against the ground-truth official scores for a few key users and add those results to the validation report. There are plenty of code inefficiencies here (row-wise operations are pretty slow) and a better approach would be to also scrape the final results and confirm they all match instead of just looking at this group. This will have to do for now though! pick_dat &lt;- entry_picks_anon %&gt;% select(-alt_name) final_scores &lt;- apply(pick_dat, 1, function(x) { # For each set of picks iterate over days map(paste0(&quot;r&quot;,1:4,&quot;_rank&quot;), ~ { day &lt;- . rank_day &lt;- score_dat %&gt;% select(player, all_of(day)) sum(rank_day[match(x, rank_day$player), day]) }) %&gt;% do.call(cbind, .) %&gt;% as_tibble %&gt;% set_names(paste0(&quot;score_&quot;, 1:4)) }) %&gt;% do.call(rbind, .) %&gt;% bind_cols(alt_name = entry_picks_anon$alt_name) test_names &lt;- c(&quot;Eastin, John&quot; = 309, #ES1 &quot;Morlock, Geya&quot; = 276, #ES2 &quot;Williams, Cameron&quot; = 242, #ES3 &quot;Ross, Macie&quot; = 252, #ES4 &quot;el-Afzal, Haazima&quot; = 279 #ES5 ) validate(final_scores, description = &quot;Validate score calculation algorithm&quot;) %&gt;% validate_if(description = &quot;Validate final scores against official scores for ES staff&quot;, all(final_scores %&gt;% filter(alt_name %in% all_of(names(test_names))) %&gt;% pull(score_4) == test_names)) %&gt;% add_results(report) Before printing the validation report let’s add one last detail that might be interesting. We were provided picks within groups, which I (maybe naively) assumed was organized approximately by player ability. The first three picks were from group A, the next three from group B, and the final two from group C. group_a &lt;- pick_dat[,1:3] %&gt;% unlist %&gt;% unique group_b &lt;- pick_dat[,4:6] %&gt;% unlist %&gt;% unique group_c &lt;- pick_dat[,7:8] %&gt;% unlist %&gt;% unique group_dict &lt;- tibble(group = c(rep(&quot;A&quot;, length(group_a)), rep(&quot;B&quot;, length(group_b)), rep(&quot;C&quot;, length(group_c))), player = c(group_a, group_b, group_c)) # Manually add 7 players from group C nobody chose man &lt;- tibble( group = &quot;C&quot;, player = c( &quot;Jim Herman&quot;, &quot;Robert Streb&quot;, &quot;Joe Long (a)&quot;, &quot;Hudson Swafford&quot;, &quot;Sandy Lyle&quot;, &quot;Fred Couples&quot;, &quot;Larry Mize&quot; ) ) group_dict &lt;- rbind(group_dict, man) Finally we print the validation report print(report) ## Validation summary: ## Number of successful validations: 7 ## Number of failed validations: 0 ## Number of validations with warnings: 0 ## ## Advanced view: ## ## ## |table_name |description |type | total_violations| ## |:------------------------------|:------------------------------------------------------------------------------------------------------------------|:-------|----------------:| ## |final_scores |Validate final scores against official scores for ES staff |success | NA| ## |Validate leaderboard data |Test that highest score matches current score. Assume all the other days are correct if passes |success | NA| ## |Validate leaderboard data |Verify ranks calculated by hand against the current position. If TRUE, assumes the other days are correct as well. |success | NA| ## |Validate player selection data |Test all 272 players are present |success | NA| ## |Validate player selection data |Test all golders are present |success | NA| ## |Validate player selection data |Test all values are 0 or 1 |success | NA| ## |Validate player selection data |Verify everyone has 8 picks and nobody has any NA |success | NA| "],["initial-data-exploration.html", "3 Initial Data Exploration 3.1 Golfer Performance 3.2 Pool Performance 3.3 Player Performance", " 3 Initial Data Exploration 3.1 Golfer Performance If we look at the leaderboard position of the full player field over time we end up with something that is a little overwhelming. We can several ties over time where ranks converge together and we can also see the cuts on day two from the straight lines from that point onwards. One thing I am a little surprised by in the beginning is that once you get out of the best few players you actually get a lot of variability in ranks over days. This makes me regret not taking a little more time to watch because I can see already that daily scores in the pool would have had some potentially big swings. # Match style being used in the slides rank_names &lt;- c(r1_rank = &quot;Day 1&quot;, r2_rank = &quot;Day 2&quot;, r3_rank = &quot;Day 3&quot;, r4_rank = &quot;Day 4&quot;) # Add indicator for players that are cut score_dat &lt;- score_dat %&gt;% mutate(cut = ifelse(is.na(pos), TRUE, FALSE)) tx_def &lt;- function() {theme_xaringan(text_font_size = 10, title_font_size = 10) } score_pdat &lt;- score_dat %&gt;% select(player, r1_rank:r4_rank, cut) %&gt;% pivot_longer(-c(player, cut)) %&gt;% mutate(name = factor(name, levels = names(rank_names), labels = rank_names)) %&gt;% left_join(group_dict) base_p &lt;- score_pdat %&gt;% ggplot(aes(x = name, y = value, group = player)) + labs(x = &quot;Day of Tournament&quot;, y = &quot;Leaderboard Position&quot;) + scale_y_reverse() + geom_line() + tx_def() base_p + labs(title = &quot;Leaderboard over time - All players&quot;) I don’t really watch a lot of golf so coming in I was expecting players that were cut were generally would have had a bad tournament from the beginning. But we can see that while this is broadly true there were actually a few players who came out strong but had a bad day two. base_p + gghighlight(cut == TRUE) We can look a little closer at the development of the top ten players over time. It looks like you get a mix of people who pretty much started and stayed there, and others who had a bad first day before finishing strong. base_p + gghighlight(min(value) &lt;= 10) + labs(title = &quot;Leaderboard over time - Ever in Top 10&quot;) Even looking at those who finished in the top 10 shows that there is a lot of room to improve and even though you can have a big drop on the second day there is still time to recover. base_p + gghighlight(last(value) &lt;= 10) + labs(title = &quot;Leaderboard over time - Finished in Top 10&quot;) Lastly let’s take a look at anyone who was ever in the top two. There were quite a few players tied for second on day three which must have made the last round exciting since they were all within striking distance of the leader. base_p + gghighlight(min(value) &lt;= 2, use_direct_label = FALSE) + labs(title = &quot;Leaderboard over time - Ever in second place&quot;) Choices for the pool were made based on groups of selections, three from group A and B and two from group C. I assumed that these roughly translated to player ability but it doesn’t seem like group was an overly strong predictor of performance. The cut includes players from all groups and the top performers in the tournament were mostly those from group B. Generally it looks like the top performers in the pool were those that made strong picks from these groups since their size relative to group A also meant they were harder to pick from. Given the large amount of variability within groups I think my original idea of fitting an HLM to identify players who performed better than their group expectation would probably not be very interesting. The original idea there was to look at predictions with/without shrinkage from hierarchical grouping but I’m not convinced it will be worth the effort considering all groups have good spread over all day four positions. score_pdat %&gt;% ggplot(aes(x = name, y = value, group = player, colour = group)) + labs(x = &quot;Day of Tournament&quot;, y = &quot;Leaderboard Position&quot;) + scale_y_reverse() + scale_colour_discrete(name = &quot;Group&quot;) + geom_line() + tx_def() score_pdat %&gt;% filter(name == &quot;Day 4&quot;) %&gt;% ggplot(aes(x = name, y = value, fill = group)) + labs(x = &quot;Day of Tournament&quot;, y = &quot;Leaderboard Position&quot;) + geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) + scale_fill_discrete(name = &quot;Group&quot;) + tx_def() 3.2 Pool Performance 3.2.1 Player Choices Player choices in each group were degined by a smaller number of “consensus” choices followed by a larger spread. The winner of the pool tended to consistently choose with the majority with the most start departure coming in group A. winner_picks &lt;- entry_picks_anon %&gt;% filter(alt_name %in% &quot;al-Saeed, Junaid&quot;) %&gt;% select(-alt_name) %&gt;% unlist entry_picks_anon %&gt;% select(-alt_name) %&gt;% gather() %&gt;% group_by(value) %&gt;% summarise(picked = n()/nrow(entry_picks_anon)) %&gt;% arrange(-picked) %&gt;% mutate(value = forcats::as_factor(value), winner = ifelse(value %in% winner_picks, TRUE,FALSE), label = ifelse(winner == TRUE, round(picked,2), &quot;&quot;)) %&gt;% left_join(group_dict, by = c(&quot;value&quot; = &quot;player&quot;)) %&gt;% mutate(group = paste(&quot;Group&quot;,group)) %&gt;% ggplot(aes(x = value, y = picked, fill = winner)) + geom_col() + geom_text(aes(label = label), hjust = 0, size = 2, angle = 90) + tx_def() + labs(y = &quot;Probability of Being Selected&quot;, x = &quot;Player&quot;) + scale_fill_discrete(name = &quot;Winner&#39;s Picks&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + facet_grid(. ~ group, scales = &quot;free&quot;, space = &quot;free_x&quot;) Correlation plots with this many dimensions are not particularly interesting or interpretable other than to say there are players that are selected together. This is partly built into to the pool since they are built into groups. Given that it might be interesting to look at plots separately. wide_dat %&gt;% select(-alt_name) %&gt;% cor(method = c(&quot;spearman&quot;)) %&gt;% ggcorrplot(type = &quot;lower&quot;,hc.order = TRUE, colors = c(plot_cols[[1]], &quot;white&quot;, plot_cols[[2]])) + tx_def() + theme(axis.text.x = element_text(size = 3), axis.text.y = element_text(size = 3)) Looking at correlation plots by selection plot doesn’t offer much extra insight other than to provide some hope that there may indeed be some sort of pattern in the golfers that are chosen together. We’ll hope for a little a little more insight into what’s going on here when we get to PCA. g_dat &lt;- group_dict %&gt;% group_by(group) %&gt;% nest map2(g_dat$data, c(8, 6, 4), ~ { wide_dat %&gt;% select(matches(.x %&gt;% pull(player))) %&gt;% cor(method = c(&quot;spearman&quot;)) %&gt;% ggcorrplot(type = &quot;lower&quot;,hc.order = TRUE, colors = c(plot_cols[[1]], &quot;white&quot;, plot_cols[[2]])) + tx_def() + theme(axis.text.x = element_text(size = .y), axis.text.y = element_text(size = .y)) }) ## [[1]] ## ## [[2]] ## ## [[3]] 3.2.1.1 EVERSANA Choices Let’s take a high-level look at how those in the money chose compared to the team from EVERSANA. It looks like you could get in the money with even a couple poor performers or some exceptionally low ranking golfers. The most striking difference between the top 5 and EVERSANA picks is that the EVERSANA picks are almost uniformally distributed over most of the range of possible positions while the top 5 generally had a high number of picks land in the top 5. Another trend can be seen in where EVERSANA agreed (eg, Bryson Dechambeau) who was not selected by any of the top 5 versus where they agreed (Justin Thomas) who was only selected by one player from EVERSANA. In some respects this could just be a matter of seeing that the people who won chose players with low scores and the people who lost didn’t, so we’ll have to bring something a little more rigorous to this down the road. top_5 &lt;- final_scores %&gt;% arrange(score_4) %&gt;% slice(1:5) %&gt;% pull(alt_name) entry_picks_anon %&gt;% filter(alt_name %in% c(names(test_names), top_5)) %&gt;% pivot_longer(-alt_name) %&gt;% left_join(score_pdat %&gt;% filter(name == &quot;Day 4&quot;) %&gt;% select(player, value) %&gt;% rename(rank = value, value = player)) %&gt;% arrange(rank) %&gt;% left_join(final_scores %&gt;% select(alt_name, score_4)) %&gt;% arrange(score_4) %&gt;% mutate( winner = ifelse(alt_name %in% top_5, &quot;Top 5&quot;, &quot;EVERSANA&quot;), alt_name = glue::glue(&quot;{alt_name} ({score_4})&quot;), value = glue::glue(&quot;{value} ({rank})&quot;), alt_name = forcats::as_factor(alt_name) ) %&gt;% arrange(rank) %&gt;% mutate(value = forcats::as_factor(value)) %&gt;% ggplot(aes(x = alt_name, y = value, colour = winner)) + geom_point() + tx_def() + scale_colour_es(name = &quot;Top 5 vs EVERSANA&quot;, &quot;primary&quot;) + labs(title = &quot;EVERSANA Player Selections&quot;, x = &quot;&quot;, y = &quot;&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 3.3 Player Performance Lastly let’s take a look at player performance. We saw that with golfers there was a big swing in the ranks over time, but how did that translate into the pool? 3.3.1 Overall p_bp &lt;- final_scores %&gt;% gather(&quot;key&quot;, &quot;value&quot;, -c(alt_name)) %&gt;% mutate(key = factor(key, labels = c(&quot;Day 1&quot;, &quot;Day 2&quot;, &quot;Day 3&quot;, &quot;Day 4&quot;))) %&gt;% group_by(key) %&gt;% arrange(key, value) %&gt;% mutate(pos = 1:n()) %&gt;% group_by(key, value) %&gt;% mutate(pos = min(pos)) %&gt;% group_by(alt_name) %&gt;% mutate(sd = sd(pos), diff = max(pos) - min(pos)) %&gt;% ggplot(aes(x = key, y = pos, group = alt_name)) + labs(x = &quot;Day of Tournament&quot;, y = &quot;Total Score&quot;) + scale_y_reverse() + geom_line() + tx_def() p_bp + labs(title = &quot;Rank - All players&quot;) So similar to the golfer situation we can see a lot of people were in the top ten at some point and there are some pretty drastic flips. We can see maybe a group of people who started of well and stayed doing well, an opposite group, and then a bunch of zig-zags somewhere in the middle. p_bp + gghighlight(min(pos) &lt;= 10) + labs(title = &quot;Leaderboard over time - Ever in Top 10&quot;) + geom_hline(yintercept = 10, colour = plot_cols[[2]]) What’s prety interesting is that it seems that most people who finished in the top 10 didn’t start there and almost half were out of the top 10 on day three. That said the winner more or less declared themselves on day two and never went back. p_bp + gghighlight(last(pos) &lt;= 10) + labs(title = &quot;Leaderboard over time - Finished in top 10&quot;) + geom_hline(yintercept = 10, colour = plot_cols[[2]]) Now let’s do the opposite of this and take a look at the worst performers. It looks like if you had a bad first day you could escape doing very poorly but it was difficult to ever to better than 150 if you were ever worse than 200. We can also see that starting well doesn’t mean anything, presumably because you a bad second day across multiple players is impossible to recover from. p_bp + gghighlight(max(pos) &gt; 200) + labs(title = &quot;Leaderboard over time - Ever worse than 200&quot;) + geom_hline(yintercept = 200, colour = plot_cols[[2]]) I think one of the most fascinating things about this tournament rank data is how much variability people have across days. So let’s highlight some groups with high variability. Using a cut-point of 50 for the standard deviation in position provides a nice grop of players who had an exciting pool. This includes people who started high and had precipitous drops as well as the opposite and then people who are somewhere in-between. p_bp + gghighlight(sd &gt; 50) + labs(title = &quot;Leaderboard over time - Rank SD &gt; 50&quot;) + geom_hline(yintercept = 200, colour = plot_cols[[2]]) Another way of looking at this is to find players who had a difference of more than 150 in their best and worst scores. p_bp + gghighlight(diff &gt; 150) + labs(title = &quot;Leaderboard over time - Difference in best and worst rank &gt; 150&quot;) + geom_hline(yintercept = 200, colour = plot_cols[[2]]) Finally let’s see the EVERSANA crew. p_bp + gghighlight(alt_name %in% names(test_names)) + labs(title = &quot;Leaderboard over time - Difference in best and worst rank &gt; 150&quot;) + geom_hline(yintercept = 200, colour = plot_cols[[2]]) "],["analysis.html", "4 Analysis 4.1 Player Choice Clustering", " 4 Analysis 4.1 Player Choice Clustering First let’s see if there’s any interesting patterns in player choices. golfer.pca &lt;- prcomp(wide_dat[,-1]) summary(golfer.pca) ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 PC6 PC7 PC8 PC9 PC10 PC11 PC12 PC13 ## Standard deviation 0.62297 0.59010 0.53747 0.5280 0.50823 0.50156 0.46683 0.45066 0.44262 0.43355 0.40197 0.39182 0.38125 ## Proportion of Variance 0.06528 0.05858 0.04859 0.0469 0.04345 0.04232 0.03666 0.03416 0.03296 0.03162 0.02718 0.02583 0.02445 ## Cumulative Proportion 0.06528 0.12386 0.17245 0.2193 0.26280 0.30512 0.34178 0.37594 0.40890 0.44051 0.46769 0.49352 0.51797 ## PC14 PC15 PC16 PC17 PC18 PC19 PC20 PC21 PC22 PC23 PC24 PC25 PC26 ## Standard deviation 0.37416 0.36402 0.35479 0.3491 0.34056 0.33048 0.32658 0.31780 0.30817 0.30574 0.29249 0.29141 0.28794 ## Proportion of Variance 0.02355 0.02229 0.02117 0.0205 0.01951 0.01837 0.01794 0.01699 0.01597 0.01572 0.01439 0.01428 0.01395 ## Cumulative Proportion 0.54152 0.56381 0.58498 0.6055 0.62499 0.64336 0.66131 0.67830 0.69427 0.70999 0.72439 0.73867 0.75262 ## PC27 PC28 PC29 PC30 PC31 PC32 PC33 PC34 PC35 PC36 PC37 PC38 PC39 ## Standard deviation 0.28300 0.27352 0.27208 0.26291 0.2558 0.25330 0.25135 0.24832 0.23910 0.23348 0.22027 0.21965 0.21697 ## Proportion of Variance 0.01347 0.01258 0.01245 0.01163 0.0110 0.01079 0.01063 0.01037 0.00962 0.00917 0.00816 0.00812 0.00792 ## Cumulative Proportion 0.76609 0.77867 0.79113 0.80275 0.8138 0.82455 0.83518 0.84555 0.85516 0.86433 0.87250 0.88061 0.88853 ## PC40 PC41 PC42 PC43 PC44 PC45 PC46 PC47 PC48 PC49 PC50 PC51 PC52 ## Standard deviation 0.20504 0.20456 0.1995 0.19582 0.19084 0.18701 0.18378 0.18289 0.18222 0.17804 0.17003 0.16669 0.1598 ## Proportion of Variance 0.00707 0.00704 0.0067 0.00645 0.00613 0.00588 0.00568 0.00563 0.00559 0.00533 0.00486 0.00467 0.0043 ## Cumulative Proportion 0.89560 0.90264 0.9093 0.91579 0.92191 0.92780 0.93348 0.93911 0.94469 0.95002 0.95489 0.95956 0.9639 ## PC53 PC54 PC55 PC56 PC57 PC58 PC59 PC60 PC61 PC62 PC63 PC64 PC65 ## Standard deviation 0.15848 0.13534 0.1244 0.12278 0.1193 0.11639 0.11340 0.10596 0.09852 0.09748 0.09228 0.08827 0.08432 ## Proportion of Variance 0.00422 0.00308 0.0026 0.00254 0.0024 0.00228 0.00216 0.00189 0.00163 0.00160 0.00143 0.00131 0.00120 ## Cumulative Proportion 0.96808 0.97116 0.9738 0.97630 0.9787 0.98098 0.98314 0.98503 0.98666 0.98826 0.98969 0.99100 0.99220 ## PC66 PC67 PC68 PC69 PC70 PC71 PC72 PC73 PC74 PC75 PC76 PC77 PC78 ## Standard deviation 0.08074 0.07811 0.07650 0.06998 0.05911 0.05795 0.05495 0.05444 0.05370 0.05088 0.04717 0.03898 0.03103 ## Proportion of Variance 0.00110 0.00103 0.00098 0.00082 0.00059 0.00056 0.00051 0.00050 0.00049 0.00044 0.00037 0.00026 0.00016 ## Cumulative Proportion 0.99329 0.99432 0.99530 0.99613 0.99672 0.99728 0.99779 0.99829 0.99877 0.99921 0.99958 0.99984 1.00000 ## PC79 PC80 PC81 ## Standard deviation 2.946e-16 1.87e-16 6.46e-17 ## Proportion of Variance 0.000e+00 0.00e+00 0.00e+00 ## Cumulative Proportion 1.000e+00 1.00e+00 1.00e+00 So unfortunately, as is usually the case, we don’t really see great performance until we hit the 30th principal component which means the plots for clustering aren’t all that informative. In an ideal world we’d see the nice situation where the first and second components explain a huge chunk of variance. Perhaps this shouldn’t be too Let’s just jump straight to kmeans on this and see if anything interesting comes up. Unfortunately the within sum of square approach is telling us we should have something like 40 clusters which is too much to be interesting. fviz_nbclust(golfer.pca$x[,1:30], kmeans, method = &quot;wss&quot;, k.max = 50) + tx_def() + theme(axis.text = element_text(size = 5)) The silhouette approach chooses k based on an assessment of how similar is a point is to its own cluster compared to other clusters. This at least gives us a reasonable answer, but everything is pointing towards it not really providing much in terms of insights (particularly since it is only suggesting two clusters). fviz_nbclust(golfer.pca$x[,1:30], kmeans, method = &quot;silhouette&quot;) + tx_def() As expected, there isn’t really any interesting about these at all. Cluster one selected better performing golfers slightly more often than cluster two but otherwise this mostly looks like noise. When this is combined with the correlation plot and the finding that the winner didn’t necessarily make a special selection of players compared to overall averages this would also suggest there weren’t really groups of players who were selected together either. Did anyone really know what they were doing? golfer.km &lt;- kmeans(golfer.pca$x[,1:30], 2) wide_dat$cluster &lt;- golfer.km$cluster wide_dat %&gt;% select(-alt_name) %&gt;% gather(key, val, - cluster) %&gt;% filter(val == 1) %&gt;% group_by(cluster,key) %&gt;% summarise(count = n()) %&gt;% group_by(cluster) %&gt;% mutate(perc = (count / sum(count) * 100)) %&gt;% left_join(score_dat %&gt;% select(player, r4_rank), by = c(&quot;key&quot; = &quot;player&quot;)) %&gt;% ungroup() %&gt;% arrange(r4_rank) %&gt;% mutate(key = forcats::as_factor(key)) %&gt;% ggplot(aes(x = key, y = perc)) + geom_col(stat = &quot;identity&quot;) + facet_wrap(~ cluster) + tx_def() + theme(axis.text.x = element_text(size = 3, angle = 90, vjust = 0.5)) Group one had slightly lower scores and slightly higher SD on average. final_scores %&gt;% left_join(wide_dat %&gt;% select(alt_name, cluster)) %&gt;% group_by(cluster) %&gt;% summarize(m = mean(score_4), sd = sd(score_4)) ## # A tibble: 2 x 3 ## cluster m sd ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 277. 65.8 ## 2 2 248. 54.1 Perhaps a simpler way to look at this is just to count the number of times any player is selected in the top 10, top 20, top 30, etc. by_ten &lt;- wide_dat %&gt;% select(-cluster) %&gt;% gather(key, val, -alt_name) %&gt;% left_join(final_scores %&gt;% select(alt_name, score_4) %&gt;% arrange(score_4) %&gt;% mutate(rank = 1:n()) %&gt;% group_by(score_4) %&gt;% mutate(rank = min(rank))) %&gt;% filter(val == 1) %&gt;% arrange(score_4) %&gt;% group_by(alt_name) %&gt;% mutate(group = case_when(rank &lt;= 10 ~ &quot;Top 10&quot;, rank &lt;= 20 ~ &quot;11-20&quot;, rank &lt;= 30 ~ &quot;21-30&quot;, rank &lt;= 40 ~ &quot;31-40&quot;, rank &lt;= 50 ~ &quot;41-50&quot;, TRUE ~ &quot;&gt;50&quot;)) by_ten %&gt;% group_by(group) %&gt;% mutate(num_g = length(unique(alt_name))) %&gt;% group_by(group,key) %&gt;% summarise(count = n(), num_g = unique(num_g)) %&gt;% mutate(perc = (count / num_g)*100) %&gt;% left_join(score_dat %&gt;% select(player, r4_rank), by = c(&quot;key&quot; = &quot;player&quot;)) %&gt;% arrange(r4_rank) %&gt;% left_join(group_dict %&gt;% rename(selected = group, key = player)) %&gt;% mutate( key = glue::glue(&quot;{key} ({r4_rank})&quot;), key = forcats::as_factor(key)) %&gt;% filter(group %in% c(&quot;Top 10&quot;, &quot;11-20&quot;, &quot;21-30&quot;)) %&gt;% ggplot(aes(x = key, y = perc, colour = group)) + geom_point() + coord_flip() + facet_grid( selected ~ group, scales = &quot;free&quot;, space = &quot;free&quot;) 4.1.1 Growth Mixture Model Another way we could look at this would be to leverage what seemed like potentially more promising data in terms of patterns of results, and maybe there are smaller groups of players that are shared in those? We can accomplish this analysis using a growth mixture model, which creates groups of players with similar trajectories. If we were doing this for a real project gmm_dat &lt;- final_scores %&gt;% gather(&quot;key&quot;, &quot;value&quot;, -c(alt_name)) %&gt;% mutate(key = factor(key, labels = c(&quot;Day 1&quot;, &quot;Day 2&quot;, &quot;Day 3&quot;, &quot;Day 4&quot;))) %&gt;% group_by(key) %&gt;% arrange(key, value) %&gt;% mutate(pos = 1:n()) %&gt;% group_by(key, value) %&gt;% mutate(pos = min(pos)) %&gt;% ungroup %&gt;% mutate(ID = as.numeric(as.factor(alt_name)), time = as.numeric(key)) lcmm1 &lt;- lcmm(pos ~ time, subject = &quot;ID&quot;, mixture = ~ time, random = ~ time, ng = 4, data = as.data.frame(gmm_dat)) ## Be patient, lcmm is running ... ## The program took 28.06 seconds preds &lt;- predictY(lcmm1, newdata = data.frame(time = c(1, 2, 3, 4)), draws = TRUE) gp_dat &lt;- gmm_dat %&gt;% left_join( lcmm1$pprob %&gt;% select(ID, class)) class_data &lt;- preds$pred %&gt;% as.data.frame %&gt;% gather %&gt;% separate(key, c(&quot;dis&quot;, &quot;int&quot;, &quot;class&quot;), &quot;_&quot;) %&gt;% group_by(int, class) %&gt;% mutate(day = paste(&quot;Day&quot;, 1:4), class = forcats::as_factor(class), class = as.numeric(class)) %&gt;% spread(int, value) gp_dat %&gt;% ggplot(aes(x = key, y = pos, group = alt_name, colour = factor(class))) + geom_line(alpha = 0.2, size = 0.3) + scale_y_reverse() + geom_line(data = class_data, inherit.aes = FALSE, size = 1, aes(x = day, y = `50`,group = class, colour = factor(class))) + scale_color_manual(values = plot_cols[1:4], name = &quot;Profile&quot;, breaks = c(3, 1, 4, 2), labels = c(&quot;Strong Performers&quot;, &quot;Improvers&quot;, &quot;Decliners&quot;, &quot;Poor Performers&quot; )) + labs(y = &quot;Player Position&quot;, x = &quot;Day of Tournament&quot;, title = &quot;Performance by Player Profile&quot;) + tx_def() The latent class model discovered trajectories that line up with what we might have expected from visual exploration. These profiles help us to see that if you were going to threaten to be in the money then you generally (but not always) start high in the leaderboard. Players in the middle could have modest improvement or worsening, and those near the bottom tended to perform poorly throughout. This was meant as a quick sandbox for playing with some tools so I haven’t done a lot of background but I was able to quickly pull some pre-masters player ranks that might provide some insights. data(&quot;p_rank&quot;) class_sels &lt;- wide_dat %&gt;% select(-cluster) %&gt;% gather(Golfer, val, -alt_name) %&gt;% filter(val == 1) %&gt;% left_join(p_rank) %&gt;% left_join(gp_dat %&gt;% select(alt_name, class)) %&gt;% mutate(class = factor(class, levels = c(3, 1, 4, 2), labels = c(&quot;Strong Performers&quot;, &quot;Improvers&quot;, &quot;Decliners&quot;, &quot;Poor Performers&quot; ))) class_sels %&gt;% group_by(alt_name) %&gt;% summarize(rank = mean(Rank), wow = sum(Rank == 176), poor = sum(Rank &gt; 100), class = unique(class)) %&gt;% group_by(class) %&gt;% select(-alt_name) %&gt;% gtsummary::tbl_summary(by = class, label = list(rank = &quot;Rank&quot;, wow = &quot;No. Unranked&quot;, poor = &quot;No. Rank &gt; 100&quot;)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #qvdgmqxofm .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qvdgmqxofm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qvdgmqxofm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qvdgmqxofm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #qvdgmqxofm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qvdgmqxofm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qvdgmqxofm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qvdgmqxofm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qvdgmqxofm .gt_column_spanner_outer:first-child { padding-left: 0; } #qvdgmqxofm .gt_column_spanner_outer:last-child { padding-right: 0; } #qvdgmqxofm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #qvdgmqxofm .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #qvdgmqxofm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qvdgmqxofm .gt_from_md > :first-child { margin-top: 0; } #qvdgmqxofm .gt_from_md > :last-child { margin-bottom: 0; } #qvdgmqxofm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qvdgmqxofm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #qvdgmqxofm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qvdgmqxofm .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #qvdgmqxofm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qvdgmqxofm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qvdgmqxofm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qvdgmqxofm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qvdgmqxofm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qvdgmqxofm .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #qvdgmqxofm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qvdgmqxofm .gt_sourcenote { font-size: 90%; padding: 4px; } #qvdgmqxofm .gt_left { text-align: left; } #qvdgmqxofm .gt_center { text-align: center; } #qvdgmqxofm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qvdgmqxofm .gt_font_normal { font-weight: normal; } #qvdgmqxofm .gt_font_bold { font-weight: bold; } #qvdgmqxofm .gt_font_italic { font-style: italic; } #qvdgmqxofm .gt_super { font-size: 65%; } #qvdgmqxofm .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic Strong Performers, N = 831 Improvers, N = 661 Decliners, N = 651 Poor Performers, N = 581 Rank 22 (20, 28) 28 (24, 36) 26 (21, 32) 34 (26, 43) No. Unranked 0 81 (98%) 59 (89%) 61 (94%) 44 (76%) 4 2 (2.4%) 7 (11%) 4 (6.2%) 12 (21%) 8 0 (0%) 0 (0%) 0 (0%) 2 (3.4%) No. Rank &gt; 100 0 67 (81%) 35 (53%) 44 (68%) 20 (34%) 4 15 (18%) 26 (39%) 17 (26%) 18 (31%) 8 1 (1.2%) 5 (7.6%) 4 (6.2%) 20 (34%) 1 Median (IQR); n (%) Strong performers chose a group of players that had on average better ranks than other groups, while poor performers trended to a higher rank. Improvers and decliners have the opposite averages than may be expected but this could be because those groups are more heterogeneous than the 4 class model separates. An alternative explanation may be that improvers and decliners either differed in terms of selecting players the over-performed or simply just that decliners got unlucky. "],["conclusions.html", "5 Conclusions 5.1 Findings 5.2 Next steps", " 5 Conclusions 5.1 Findings Participants in the masters pool did not appear to show clusters of golfer choices. My original hypothesis was that actual golfers themselves would be selected in groups by pool participants who actually followed golf but player selections themselves were generally uncorrelated. This lead to poor performance on PCA and subsequently a mostly meaningless kmeans clustering exercise. Participant performance could be reasonably described by their membership in one of four profiles. Strong performers started and finished higher on the leaderboard and generally selected players whose pre-masters PGA ranking was lower than those in other groups. Poor performers chose players with higher PGA ranks and were more likely to choose unranked golfers or golfers with ranks worse than 100. Improvers and Decliners chose similarly ranked golfers although point estimates were different than expected. In future work it might be interesting to see how a kmeans or longitudinal kmeans would have performed on the outcome data although the GMM framework is nice and worked well in this case. 5.2 Next steps This was a nice introduction to some applied clustering on characteristics/outcomes for me. It was a great opportunity to actually work through an example where clustering on characteristics (player choice) did not provide much insight but clustering on outcome did. Next steps for me will be to start to build a workflow around these tools, and investigate some other options (eg, infinite mixture models). Overall I am very happy with the packages used in this project. I would definitely use gghighlight again. In the future I might want to play a little more with animations. "]]
